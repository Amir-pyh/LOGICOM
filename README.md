# LOGICOM (To be updated)

[How susceptible are LLMs to Logical Fallacies?](https://arxiv.org/abs/2308.09853)

This work investigates the rational thinking capability of
Large Language Models (LLMs) in multi-round argumentative debate
we present **Log**ic **Co**mpetence **M**easurement Benchmark (LOGICOM), a diagnostic benchmark to assess the robustness of LLMs against logical fallacies.

<figure>
  <img src="https://github.com/Amir-pyh/LOGICOM/blob/main/figs/LOGICOM-LARG.png" alt="Alt text for image" style="width:100%">
  <figcaption> LOGICOM: A demonstration of three scenarios evaluating LLMsâ€™ reasoning skills and vulnerability to logical fallacies. </figcaption>
</figure>

## Results

## Citation
```bibtex
@misc{payandeh2023susceptible,
      title={How susceptible are LLMs to Logical Fallacies?},
      author={Amirreza Payandeh and Dan Pluth and Jordan Hosier and Xuesu Xiao and Vijay K. Gurbani},
      year={2023},
      eprint={2308.09853},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
```
